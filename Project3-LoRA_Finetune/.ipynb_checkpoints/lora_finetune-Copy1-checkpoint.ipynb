{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "collapsed": false,
    "id": "89b89f64d8f8053d",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB及以上（推荐使用30系或A10等sm80架构以上的NVIDIA显卡进行尝试）\n",
    "内存：16GB\n",
    "RAM: 2.9 /16 GB\n",
    "GPU RAM: 15.5/16.0 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "collapsed": false,
    "id": "a7bd9a514ed09ea6",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 0. 环境检查\n",
    "首先，先检查代码的运行地址，确保运行地址处于 `finetune_demo` 中。\n",
    "并且，确保已经安装了 `requirements.txt`中的依赖。\n",
    "\n",
    "> 本 demo 中，不需要使用 deepspeed, mpi4py 两个依赖，如果您安装这两个依赖遇到问题，可以不安装这两个依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7703109d1443346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T05:29:22.200365Z",
     "start_time": "2024-04-14T05:29:22.080929Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/zr/Data/Code/ChatGLM3/finetune_demo\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d1b1d9-c94b-4542-98b9-60df35e15c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.virtaicloud.com/repository/pypi/simple\n",
      "Collecting jieba>=0.42.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/jieba/0.42.1/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m149.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ruamel_yaml>=0.18.6 (from -r requirements.txt (line 2))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/ruamel-yaml/0.18.6/ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge_chinese>=1.0.3 (from -r requirements.txt (line 3))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/rouge-chinese/1.0.3/rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Collecting jupyter>=1.0.0 (from -r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/jupyter/1.0.0/jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: datasets>=2.18.0 in /root/miniconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.18.0)\n",
      "Collecting peft>=0.10.0 (from -r requirements.txt (line 6))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/peft/0.12.0/peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m255.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting deepspeed==0.13.1 (from -r requirements.txt (line 7))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/deepspeed/0.13.1/deepspeed-0.13.1.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: hjson in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: ninja in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (1.11.1.1)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (9.0.0)\n",
      "Requirement already satisfied: pydantic in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (2.7.1)\n",
      "Requirement already satisfied: pynvml in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (11.5.0)\n",
      "Requirement already satisfied: torch in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.11/site-packages (from deepspeed==0.13.1->-r requirements.txt (line 7)) (4.65.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel_yaml>=0.18.6->-r requirements.txt (line 2))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/ruamel-yaml-clib/0.2.8/ruamel.yaml.clib-0.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (544 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.0/544.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /root/miniconda3/lib/python3.11/site-packages (from rouge_chinese>=1.0.3->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting notebook (from jupyter>=1.0.0->-r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/notebook/7.2.1/notebook-7.2.1-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting qtconsole (from jupyter>=1.0.0->-r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/qtconsole/5.5.2/qtconsole-5.5.2-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter-console (from jupyter>=1.0.0->-r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/jupyter-console/6.6.3/jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: nbconvert in /root/miniconda3/lib/python3.11/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /root/miniconda3/lib/python3.11/site-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (6.29.4)\n",
      "Collecting ipywidgets (from jupyter>=1.0.0->-r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/ipywidgets/8.1.3/ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m188.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /root/miniconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.18.0->-r requirements.txt (line 5)) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (0.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.11/site-packages (from datasets>=2.18.0->-r requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.11/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (4.40.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/lib/python3.11/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (0.30.1)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/lib/python3.11/site-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (0.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.18.0->-r requirements.txt (line 5)) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets>=2.18.0->-r requirements.txt (line 5)) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.18.0->-r requirements.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.18.0->-r requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.18.0->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.18.0->-r requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /root/miniconda3/lib/python3.11/site-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (12.4.127)\n",
      "Requirement already satisfied: comm>=0.1.1 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (8.24.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /root/miniconda3/lib/python3.11/site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.11 (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/widgetsnbextension/4.0.11/widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-widgets~=3.0.11 (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/jupyterlab-widgets/3.0.11/jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m217.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.30 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.43)\n",
      "Requirement already satisfied: pygments in /root/miniconda3/lib/python3.11/site-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /root/miniconda3/lib/python3.11/site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /root/miniconda3/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.14.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /root/miniconda3/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.27.1)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in /root/miniconda3/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.2.0)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /root/miniconda3/lib/python3.11/site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.11/site-packages (from pandas->datasets>=2.18.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.11/site-packages (from pandas->datasets>=2.18.0->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.11/site-packages (from pandas->datasets>=2.18.0->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/miniconda3/lib/python3.11/site-packages (from pydantic->deepspeed==0.13.1->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /root/miniconda3/lib/python3.11/site-packages (from pydantic->deepspeed==0.13.1->-r requirements.txt (line 7)) (2.18.2)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter>=1.0.0->-r requirements.txt (line 4))\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/qtpy/2.4.1/QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m167.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.11/site-packages (from transformers->peft>=0.10.0->-r requirements.txt (line 6)) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /root/miniconda3/lib/python3.11/site-packages (from transformers->peft>=0.10.0->-r requirements.txt (line 6)) (0.19.1)\n",
      "Requirement already satisfied: webencodings in /root/miniconda3/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.5.1)\n",
      "Requirement already satisfied: decorator in /root/miniconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /root/miniconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /root/miniconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /root/miniconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.20.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.2.5)\n",
      "Requirement already satisfied: babel>=2.10 in /root/miniconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.15.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /root/miniconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.22.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /root/miniconda3/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.19.1)\n",
      "Requirement already satisfied: wcwidth in /root/miniconda3/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /root/miniconda3/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.11/site-packages (from sympy->torch->deepspeed==0.13.1->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /root/miniconda3/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (21.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /root/miniconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /root/miniconda3/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /root/miniconda3/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /root/miniconda3/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.18.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /root/miniconda3/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /root/miniconda3/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/miniconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /root/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /root/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /root/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.2)\n",
      "Requirement already satisfied: fqdn in /root/miniconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /root/miniconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /root/miniconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.1)\n",
      "Requirement already satisfied: uri-template in /root/miniconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /root/miniconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /root/miniconda3/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /root/miniconda3/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /root/miniconda3/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.9.0.20240316)\n",
      "Building wheels for collected packages: deepspeed, jieba\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.13.1-py3-none-any.whl size=1350302 sha256=044fb7bb4ec10a9ec194a8aba3bf5f56d4d3d57de97609c0a764719177157dee\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/70/12/8a0a6d87e9601c77faa51ad9c048c35d0c099fab735418ab79\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=70d2e45a07ccd9b923fd40ff5d277170d888d4d6d1de3b82d60fd5233b110051\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/13/a3/1085bb7139402a18fc673273370453d3d6cd075cd993032323\n",
      "Successfully built deepspeed jieba\n",
      "Installing collected packages: jieba, widgetsnbextension, ruamel.yaml.clib, rouge_chinese, qtpy, jupyterlab-widgets, ruamel_yaml, ipywidgets, deepspeed, qtconsole, peft, jupyter-console, notebook, jupyter\n",
      "  Attempting uninstall: ruamel_yaml\n",
      "    Found existing installation: ruamel.yaml 0.17.21\n",
      "    Uninstalling ruamel.yaml-0.17.21:\n",
      "      Successfully uninstalled ruamel.yaml-0.17.21\n",
      "  Attempting uninstall: deepspeed\n",
      "    Found existing installation: deepspeed 0.14.2\n",
      "    Uninstalling deepspeed-0.14.2:\n",
      "      Successfully uninstalled deepspeed-0.14.2\n",
      "Successfully installed deepspeed-0.13.1 ipywidgets-8.1.3 jieba-0.42.1 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.11 notebook-7.2.1 peft-0.12.0 qtconsole-5.5.2 qtpy-2.4.1 rouge_chinese-1.0.3 ruamel.yaml.clib-0.2.8 ruamel_yaml-0.18.6 widgetsnbextension-4.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc52df2b-c24c-4fa2-9b67-18f3f7fb6df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.virtaicloud.com/repository/pypi/simple\n",
      "Collecting nltk\n",
      "  Downloading https://pypi.virtaicloud.com/repository/pypi/packages/nltk/3.8.1/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /root/miniconda3/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /root/miniconda3/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /root/miniconda3/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50e92810011977",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T05:29:23.809255Z",
     "start_time": "2024-04-14T05:29:22.202731Z"
    },
    "cellView": "form",
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "collapsed": false,
    "id": "a1b7a99923349056",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c87410a24d844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T06:23:41.282431Z",
     "start_time": "2024-04-14T05:29:23.810692Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17c87410a24d844f",
    "outputId": "e347fc7d-875e-40c9-c682-3e064100476b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config file: /etc/orion/env/env.conf\n",
      "Loading checkpoint shards:   0%|                          | 0/7 [00:00<?, ?it/s]/root/miniconda3/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [03:03<00:00, 26.19s/it]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.0312\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 114599 examples [00:00, 604678.34 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
      "Generating validation split: 1070 examples [00:00, 155808.40 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
      "Generating test split: 1070 examples [00:00, 119642.38 examples/s]\n",
      "Map (num_proc=16): 100%|██████| 114599/114599 [00:03<00:00, 34127.65 examples/s]\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 1407.12 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 1443.05 examples/s]\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]/root/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 4.8297, 'grad_norm': 2.297297716140747, 'learning_rate': 4.9833333333333336e-05, 'epoch': 0.0}\n",
      "{'loss': 4.6, 'grad_norm': 3.25954270362854, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 4.4816, 'grad_norm': 3.063594102859497, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1146, 'grad_norm': 3.4460537433624268, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1084, 'grad_norm': 2.7971348762512207, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8631, 'grad_norm': 3.021066188812256, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8361, 'grad_norm': 2.9395554065704346, 'learning_rate': 4.883333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7432, 'grad_norm': 3.0225162506103516, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6307, 'grad_norm': 3.3005809783935547, 'learning_rate': 4.85e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7156, 'grad_norm': 3.4904370307922363, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6693, 'grad_norm': 3.6740565299987793, 'learning_rate': 4.8166666666666674e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8459, 'grad_norm': 3.947591781616211, 'learning_rate': 4.8e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6125, 'grad_norm': 3.524169683456421, 'learning_rate': 4.7833333333333335e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7283, 'grad_norm': 4.487576961517334, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6836, 'grad_norm': 3.7072529792785645, 'learning_rate': 4.75e-05, 'epoch': 0.01}\n",
      "{'loss': 3.7414, 'grad_norm': 3.985466718673706, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5734, 'grad_norm': 4.119104862213135, 'learning_rate': 4.716666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5734, 'grad_norm': 4.354592800140381, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5477, 'grad_norm': 4.840324878692627, 'learning_rate': 4.683333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.577, 'grad_norm': 4.553428649902344, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.549, 'grad_norm': 4.974406719207764, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6477, 'grad_norm': 4.1121602058410645, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6133, 'grad_norm': 4.77501916885376, 'learning_rate': 4.6166666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5078, 'grad_norm': 4.527997016906738, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4762, 'grad_norm': 5.380683422088623, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6033, 'grad_norm': 5.279057025909424, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.551, 'grad_norm': 5.402585983276367, 'learning_rate': 4.55e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6145, 'grad_norm': 4.5536346435546875, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6307, 'grad_norm': 4.794005393981934, 'learning_rate': 4.516666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5445, 'grad_norm': 5.815830230712891, 'learning_rate': 4.5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4691, 'grad_norm': 5.280670166015625, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6063, 'grad_norm': 5.751097202301025, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4176, 'grad_norm': 5.237898349761963, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4941, 'grad_norm': 5.313364505767822, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5215, 'grad_norm': 5.553865909576416, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5754, 'grad_norm': 5.247211933135986, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3609, 'grad_norm': 4.903344631195068, 'learning_rate': 4.383333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5299, 'grad_norm': 5.207480430603027, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.526, 'grad_norm': 5.2737650871276855, 'learning_rate': 4.35e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4752, 'grad_norm': 5.664404392242432, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6926, 'grad_norm': 5.531679630279541, 'learning_rate': 4.316666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4969, 'grad_norm': 5.031117916107178, 'learning_rate': 4.3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6266, 'grad_norm': 5.687654972076416, 'learning_rate': 4.2833333333333335e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4164, 'grad_norm': 6.524467945098877, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4156, 'grad_norm': 6.01779317855835, 'learning_rate': 4.25e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4271, 'grad_norm': 5.617354393005371, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5346, 'grad_norm': 5.765071392059326, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4484, 'grad_norm': 7.0472307205200195, 'learning_rate': 4.2e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4607, 'grad_norm': 5.848387241363525, 'learning_rate': 4.183333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5643, 'grad_norm': 5.9743332862854, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [07:32<41:04,  1.01it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.38s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.74s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  6.39s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.529 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001b[A{'eval_rouge-1': 31.301926, 'eval_rouge-2': 7.004397999999998, 'eval_rouge-l': 24.706428000000002, 'eval_bleu-4': 0.033997401984267775, 'eval_runtime': 23.3541, 'eval_samples_per_second': 2.141, 'eval_steps_per_second': 0.171, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [07:56<41:04,  1.01it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:20<00:00,  6.39s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-500\n",
      "loading configuration file /gemini/pretrain/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3232, 'grad_norm': 5.878652095794678, 'learning_rate': 4.15e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5486, 'grad_norm': 6.6891937255859375, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5799, 'grad_norm': 6.082517147064209, 'learning_rate': 4.116666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4883, 'grad_norm': 5.448827743530273, 'learning_rate': 4.1e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5232, 'grad_norm': 5.411219120025635, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.6469, 'grad_norm': 5.801650524139404, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.492, 'grad_norm': 5.86314058303833, 'learning_rate': 4.05e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3736, 'grad_norm': 5.622318267822266, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.02}\n",
      "{'loss': 3.427, 'grad_norm': 6.2592267990112305, 'learning_rate': 4.016666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4922, 'grad_norm': 6.534326553344727, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4408, 'grad_norm': 6.231381416320801, 'learning_rate': 3.983333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4594, 'grad_norm': 6.7406768798828125, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4484, 'grad_norm': 6.0261335372924805, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4574, 'grad_norm': 6.172551155090332, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5346, 'grad_norm': 5.944576740264893, 'learning_rate': 3.9166666666666665e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4855, 'grad_norm': 6.343961715698242, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5484, 'grad_norm': 6.163320064544678, 'learning_rate': 3.883333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.308, 'grad_norm': 7.222947597503662, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.399, 'grad_norm': 6.574150085449219, 'learning_rate': 3.85e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3521, 'grad_norm': 6.366031169891357, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.501, 'grad_norm': 7.097790241241455, 'learning_rate': 3.816666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5277, 'grad_norm': 6.875953674316406, 'learning_rate': 3.8e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2465, 'grad_norm': 6.9865875244140625, 'learning_rate': 3.7833333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5756, 'grad_norm': 5.915491580963135, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3975, 'grad_norm': 6.557424068450928, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4777, 'grad_norm': 6.1544294357299805, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.6203, 'grad_norm': 6.444244861602783, 'learning_rate': 3.7166666666666664e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4746, 'grad_norm': 6.293545722961426, 'learning_rate': 3.7e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3273, 'grad_norm': 6.556063652038574, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5529, 'grad_norm': 7.000132083892822, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2908, 'grad_norm': 6.587034225463867, 'learning_rate': 3.65e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3609, 'grad_norm': 6.564496994018555, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4621, 'grad_norm': 7.316718101501465, 'learning_rate': 3.6166666666666674e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4082, 'grad_norm': 6.431578636169434, 'learning_rate': 3.6e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5064, 'grad_norm': 6.257224082946777, 'learning_rate': 3.5833333333333335e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5369, 'grad_norm': 6.352939128875732, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2955, 'grad_norm': 7.220691204071045, 'learning_rate': 3.55e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4926, 'grad_norm': 6.8397016525268555, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4551, 'grad_norm': 7.4574737548828125, 'learning_rate': 3.516666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2656, 'grad_norm': 8.054319381713867, 'learning_rate': 3.5e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4604, 'grad_norm': 7.958688735961914, 'learning_rate': 3.483333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4209, 'grad_norm': 6.938246726989746, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4604, 'grad_norm': 7.58400821685791, 'learning_rate': 3.45e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5672, 'grad_norm': 7.397481441497803, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3598, 'grad_norm': 6.51149845123291, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4379, 'grad_norm': 7.837721824645996, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5344, 'grad_norm': 5.968639850616455, 'learning_rate': 3.3833333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.326, 'grad_norm': 7.152941703796387, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4625, 'grad_norm': 7.472070217132568, 'learning_rate': 3.35e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4002, 'grad_norm': 8.025094985961914, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [15:08<29:52,  1.12it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.34s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.72s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.03454000000001, 'eval_rouge-2': 6.471912, 'eval_rouge-l': 25.303188, 'eval_bleu-4': 0.03199581503220256, 'eval_runtime': 9.6627, 'eval_samples_per_second': 5.175, 'eval_steps_per_second': 0.414, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [15:17<29:52,  1.12it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1000\n",
      "loading configuration file /gemini/pretrain/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.4492, 'grad_norm': 7.01421594619751, 'learning_rate': 3.316666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4605, 'grad_norm': 7.5058722496032715, 'learning_rate': 3.3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6498, 'grad_norm': 8.285473823547363, 'learning_rate': 3.283333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3996, 'grad_norm': 6.551565170288086, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3932, 'grad_norm': 8.742742538452148, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3588, 'grad_norm': 7.796103477478027, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3908, 'grad_norm': 7.261214733123779, 'learning_rate': 3.2166666666666665e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4617, 'grad_norm': 7.310837268829346, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5311, 'grad_norm': 7.242465972900391, 'learning_rate': 3.183333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4678, 'grad_norm': 6.671215057373047, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.04}\n",
      "{'loss': 3.348, 'grad_norm': 6.910529136657715, 'learning_rate': 3.15e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5248, 'grad_norm': 7.986298561096191, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4357, 'grad_norm': 7.4513421058654785, 'learning_rate': 3.116666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3607, 'grad_norm': 8.219488143920898, 'learning_rate': 3.1e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3215, 'grad_norm': 7.571022987365723, 'learning_rate': 3.0833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3627, 'grad_norm': 7.343061923980713, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4531, 'grad_norm': 6.75761604309082, 'learning_rate': 3.05e-05, 'epoch': 0.04}\n",
      "{'loss': 3.473, 'grad_norm': 6.518359661102295, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3584, 'grad_norm': 6.677292823791504, 'learning_rate': 3.016666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.41, 'grad_norm': 6.493782043457031, 'learning_rate': 3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2437, 'grad_norm': 6.683138847351074, 'learning_rate': 2.9833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.342, 'grad_norm': 7.5631422996521, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3797, 'grad_norm': 7.5921430587768555, 'learning_rate': 2.95e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3766, 'grad_norm': 8.256733894348145, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4469, 'grad_norm': 6.874446392059326, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2822, 'grad_norm': 7.666890621185303, 'learning_rate': 2.9e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4543, 'grad_norm': 7.218358993530273, 'learning_rate': 2.8833333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3357, 'grad_norm': 7.379914283752441, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3937, 'grad_norm': 7.079039573669434, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4816, 'grad_norm': 7.469693660736084, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4643, 'grad_norm': 7.004300117492676, 'learning_rate': 2.816666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.452, 'grad_norm': 6.786288261413574, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4016, 'grad_norm': 10.746150970458984, 'learning_rate': 2.7833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3074, 'grad_norm': 7.666667938232422, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3525, 'grad_norm': 7.6446380615234375, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3008, 'grad_norm': 8.029380798339844, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5201, 'grad_norm': 7.360688209533691, 'learning_rate': 2.716666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.385, 'grad_norm': 7.188716411590576, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3586, 'grad_norm': 7.120919704437256, 'learning_rate': 2.6833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.418, 'grad_norm': 6.730539798736572, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3514, 'grad_norm': 7.53222131729126, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2676, 'grad_norm': 7.813169002532959, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3795, 'grad_norm': 7.774684429168701, 'learning_rate': 2.6166666666666668e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3592, 'grad_norm': 7.264221668243408, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2687, 'grad_norm': 6.98321008682251, 'learning_rate': 2.5833333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3916, 'grad_norm': 7.337331295013428, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4371, 'grad_norm': 9.38465404510498, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3023, 'grad_norm': 6.772063255310059, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4414, 'grad_norm': 7.4686994552612305, 'learning_rate': 2.5166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4617, 'grad_norm': 6.961489200592041, 'learning_rate': 2.5e-05, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [22:28<19:11,  1.30it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.48s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.96s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.856162000000005, 'eval_rouge-2': 6.949947999999999, 'eval_rouge-l': 25.633464, 'eval_bleu-4': 0.035154163775236016, 'eval_runtime': 11.0534, 'eval_samples_per_second': 4.523, 'eval_steps_per_second': 0.362, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [22:39<19:11,  1.30it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:07<00:00,  1.90s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1500\n",
      "loading configuration file /gemini/pretrain/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3434, 'grad_norm': 7.055859088897705, 'learning_rate': 2.4833333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3904, 'grad_norm': 8.341836929321289, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4406, 'grad_norm': 8.260720252990723, 'learning_rate': 2.45e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4037, 'grad_norm': 7.240734577178955, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4934, 'grad_norm': 7.391683578491211, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4057, 'grad_norm': 8.55430793762207, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4705, 'grad_norm': 8.10240650177002, 'learning_rate': 2.3833333333333334e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4377, 'grad_norm': 7.640324115753174, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5127, 'grad_norm': 9.331146240234375, 'learning_rate': 2.35e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3937, 'grad_norm': 7.096501350402832, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3723, 'grad_norm': 8.034991264343262, 'learning_rate': 2.3166666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3705, 'grad_norm': 8.517125129699707, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4752, 'grad_norm': 7.5257039070129395, 'learning_rate': 2.2833333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3182, 'grad_norm': 8.207610130310059, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3711, 'grad_norm': 7.58718204498291, 'learning_rate': 2.25e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3051, 'grad_norm': 7.1018805503845215, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4799, 'grad_norm': 8.821365356445312, 'learning_rate': 2.216666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3754, 'grad_norm': 7.249484539031982, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3805, 'grad_norm': 7.454407691955566, 'learning_rate': 2.1833333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5211, 'grad_norm': 7.085261344909668, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4666, 'grad_norm': 7.338024616241455, 'learning_rate': 2.15e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5031, 'grad_norm': 7.469071865081787, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4053, 'grad_norm': 7.617613315582275, 'learning_rate': 2.116666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4, 'grad_norm': 7.670391082763672, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4727, 'grad_norm': 7.555857181549072, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4449, 'grad_norm': 7.827686309814453, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3623, 'grad_norm': 8.464568138122559, 'learning_rate': 2.05e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3553, 'grad_norm': 8.168076515197754, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3955, 'grad_norm': 8.41472053527832, 'learning_rate': 2.0166666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3424, 'grad_norm': 7.922582149505615, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3791, 'grad_norm': 8.968347549438477, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3404, 'grad_norm': 7.654489517211914, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.584, 'grad_norm': 7.975806713104248, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3465, 'grad_norm': 8.683838844299316, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4936, 'grad_norm': 9.170309066772461, 'learning_rate': 1.9166666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.383, 'grad_norm': 7.412587642669678, 'learning_rate': 1.9e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3178, 'grad_norm': 8.147418975830078, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3086, 'grad_norm': 7.5707221031188965, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4021, 'grad_norm': 7.538513660430908, 'learning_rate': 1.85e-05, 'epoch': 0.07}\n",
      "{'loss': 3.377, 'grad_norm': 7.9650750160217285, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3922, 'grad_norm': 8.212199211120605, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4793, 'grad_norm': 7.48213529586792, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2816, 'grad_norm': 7.9129414558410645, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.502, 'grad_norm': 7.89762020111084, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3646, 'grad_norm': 7.006743907928467, 'learning_rate': 1.75e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2859, 'grad_norm': 8.776000022888184, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3719, 'grad_norm': 7.70494270324707, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2406, 'grad_norm': 7.753202438354492, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4203, 'grad_norm': 7.288348197937012, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4697, 'grad_norm': 8.002068519592285, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [29:51<13:54,  1.20it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.58s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:20<00:07,  7.97s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 30.104656, 'eval_rouge-2': 6.233702000000002, 'eval_rouge-l': 23.026049999999994, 'eval_bleu-4': 0.0314820918529419, 'eval_runtime': 40.6853, 'eval_samples_per_second': 1.229, 'eval_steps_per_second': 0.098, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [30:31<13:54,  1.20it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:22<00:00,  5.89s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2000\n",
      "loading configuration file /gemini/pretrain/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3893, 'grad_norm': 8.82780933380127, 'learning_rate': 1.65e-05, 'epoch': 0.07}\n",
      "{'loss': 3.499, 'grad_norm': 7.599987030029297, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5598, 'grad_norm': 8.871994972229004, 'learning_rate': 1.6166666666666665e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4937, 'grad_norm': 8.28796100616455, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3717, 'grad_norm': 8.258803367614746, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3379, 'grad_norm': 7.920660495758057, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4418, 'grad_norm': 8.203740119934082, 'learning_rate': 1.55e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4199, 'grad_norm': 8.256528854370117, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.44, 'grad_norm': 7.561687469482422, 'learning_rate': 1.5166666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3611, 'grad_norm': 7.833284854888916, 'learning_rate': 1.5e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2955, 'grad_norm': 7.8165154457092285, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5828, 'grad_norm': 8.005536079406738, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2527, 'grad_norm': 7.80866003036499, 'learning_rate': 1.45e-05, 'epoch': 0.07}\n",
      "{'loss': 3.367, 'grad_norm': 8.311955451965332, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3994, 'grad_norm': 7.370458602905273, 'learning_rate': 1.4166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.5172, 'grad_norm': 8.11068058013916, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3984, 'grad_norm': 6.856274604797363, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4141, 'grad_norm': 7.931201934814453, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3561, 'grad_norm': 7.776516914367676, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4363, 'grad_norm': 7.763903617858887, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4506, 'grad_norm': 7.0263895988464355, 'learning_rate': 1.3166666666666665e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4215, 'grad_norm': 7.772670269012451, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4225, 'grad_norm': 8.196760177612305, 'learning_rate': 1.2833333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3754, 'grad_norm': 8.501155853271484, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2402, 'grad_norm': 8.500404357910156, 'learning_rate': 1.25e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3654, 'grad_norm': 8.033329010009766, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4332, 'grad_norm': 8.748231887817383, 'learning_rate': 1.2166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4621, 'grad_norm': 7.810093879699707, 'learning_rate': 1.2e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2938, 'grad_norm': 8.381772994995117, 'learning_rate': 1.1833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.359, 'grad_norm': 8.504591941833496, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3217, 'grad_norm': 8.496014595031738, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3299, 'grad_norm': 8.526078224182129, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3691, 'grad_norm': 8.946611404418945, 'learning_rate': 1.1166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3637, 'grad_norm': 7.960535526275635, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2738, 'grad_norm': 8.755915641784668, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3828, 'grad_norm': 8.217337608337402, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3547, 'grad_norm': 8.049448013305664, 'learning_rate': 1.05e-05, 'epoch': 0.08}\n",
      "{'loss': 3.5002, 'grad_norm': 8.597853660583496, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2406, 'grad_norm': 8.654748916625977, 'learning_rate': 1.0166666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4625, 'grad_norm': 7.903940200805664, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4584, 'grad_norm': 8.328081130981445, 'learning_rate': 9.833333333333333e-06, 'epoch': 0.08}\n",
      "{'loss': 3.2834, 'grad_norm': 8.162449836730957, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.08}\n",
      "{'loss': 3.3758, 'grad_norm': 7.3449387550354, 'learning_rate': 9.5e-06, 'epoch': 0.08}\n",
      "{'loss': 3.382, 'grad_norm': 8.070015907287598, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.277, 'grad_norm': 7.836854457855225, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3139, 'grad_norm': 7.73779821395874, 'learning_rate': 9e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2604, 'grad_norm': 8.82217025756836, 'learning_rate': 8.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4381, 'grad_norm': 7.576902389526367, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4771, 'grad_norm': 7.907273769378662, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3922, 'grad_norm': 9.600545883178711, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [37:42<06:59,  1.19it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.44s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.79s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.549308, 'eval_rouge-2': 7.275242, 'eval_rouge-l': 24.720080000000003, 'eval_bleu-4': 0.03474575142906994, 'eval_runtime': 25.316, 'eval_samples_per_second': 1.975, 'eval_steps_per_second': 0.158, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [38:07<06:59,  1.19it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:07<00:00,  1.92s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2500\n",
      "loading configuration file /gemini/pretrain/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3023, 'grad_norm': 8.490738868713379, 'learning_rate': 8.166666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.342, 'grad_norm': 11.039189338684082, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2494, 'grad_norm': 8.070608139038086, 'learning_rate': 7.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3963, 'grad_norm': 8.117138862609863, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3926, 'grad_norm': 7.890193939208984, 'learning_rate': 7.5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4053, 'grad_norm': 8.468483924865723, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4721, 'grad_norm': 8.116192817687988, 'learning_rate': 7.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.483, 'grad_norm': 8.738410949707031, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3805, 'grad_norm': 8.463850021362305, 'learning_rate': 6.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4828, 'grad_norm': 8.772858619689941, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3578, 'grad_norm': 8.084059715270996, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4273, 'grad_norm': 7.760975360870361, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.5232, 'grad_norm': 7.63082218170166, 'learning_rate': 6.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4496, 'grad_norm': 8.687474250793457, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4127, 'grad_norm': 8.096834182739258, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3533, 'grad_norm': 8.020503997802734, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.407, 'grad_norm': 8.720816612243652, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2725, 'grad_norm': 7.759737014770508, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4787, 'grad_norm': 8.735422134399414, 'learning_rate': 5.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.45, 'grad_norm': 8.966642379760742, 'learning_rate': 5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4316, 'grad_norm': 8.436781883239746, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2523, 'grad_norm': 7.707430362701416, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.383, 'grad_norm': 8.043000221252441, 'learning_rate': 4.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3885, 'grad_norm': 8.16854190826416, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4582, 'grad_norm': 9.195045471191406, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4004, 'grad_norm': 8.300350189208984, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3516, 'grad_norm': 8.465397834777832, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2621, 'grad_norm': 8.742588996887207, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2834, 'grad_norm': 8.305449485778809, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2457, 'grad_norm': 7.852000713348389, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4492, 'grad_norm': 7.906507968902588, 'learning_rate': 3.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3762, 'grad_norm': 8.086462020874023, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3898, 'grad_norm': 8.104175567626953, 'learning_rate': 2.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.443, 'grad_norm': 9.08471965789795, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4062, 'grad_norm': 8.657105445861816, 'learning_rate': 2.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3365, 'grad_norm': 8.511092185974121, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3768, 'grad_norm': 8.67184829711914, 'learning_rate': 2.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.5107, 'grad_norm': 9.193046569824219, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3084, 'grad_norm': 8.088168144226074, 'learning_rate': 1.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3273, 'grad_norm': 9.084969520568848, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3102, 'grad_norm': 7.914985179901123, 'learning_rate': 1.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2486, 'grad_norm': 7.417332649230957, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3604, 'grad_norm': 8.905035972595215, 'learning_rate': 1.1666666666666668e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2588, 'grad_norm': 8.520608901977539, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3813, 'grad_norm': 8.08544635772705, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.1}\n",
      "{'loss': 3.2092, 'grad_norm': 9.135297775268555, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4479, 'grad_norm': 8.983114242553711, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4295, 'grad_norm': 9.151205062866211, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4756, 'grad_norm': 8.16067123413086, 'learning_rate': 1.6666666666666668e-07, 'epoch': 0.1}\n",
      "{'loss': 3.3719, 'grad_norm': 8.070587158203125, 'learning_rate': 0.0, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [45:19<00:00,  1.23it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.38s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:02,  2.01s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.451876000000006, 'eval_rouge-2': 7.044398000000001, 'eval_rouge-l': 24.276421999999997, 'eval_bleu-4': 0.03307901037253243, 'eval_runtime': 37.696, 'eval_samples_per_second': 1.326, 'eval_steps_per_second': 0.106, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [45:57<00:00,  1.23it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:20<00:00,  6.55s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-3000\n",
      "loading configuration file /gemini/pretrain/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 2758.197, 'train_samples_per_second': 4.351, 'train_steps_per_second': 1.088, 'train_loss': 3.447501953125, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [45:58<00:00,  1.09it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [10:37<00:00,  9.51s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python finetune_hf.py  data/AdvertiseGen_fix  /gemini/pretrain  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418f6c5c264601",
   "metadata": {
    "collapsed": false,
    "id": "d9418f6c5c264601",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. 使用微调的数据集进行推理\n",
    "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
    "我们选择最后一轮的微调权重，并使用inference进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5060015c24e97ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T06:23:52.725227Z",
     "start_time": "2024-04-14T06:23:41.284552Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5060015c24e97ae",
    "outputId": "d3f03d0d-46bf-4c74-9b00-dc0160da0e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:02<00:00,  2.45it/s]\r\n",
      "Setting eos_token is not supported, use the default one.\r\n",
      "Setting pad_token is not supported, use the default one.\r\n",
      "Setting unk_token is not supported, use the default one.\r\n",
      "这款连衣裙采用压褶的版型设计，不规则的木耳边拼接，修饰了腰线，使得身材更加修长，不规则的压褶设计，增加了层次感，不规则的压褶，修饰了腰线，拉长腿部比例，显瘦又性感，套头的设计，方便穿脱，不规则的压褶，增加层次感，视觉上拉长腿部比例，百褶的网纱拼接，增加了层次感，整体气质优雅。\r\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-4000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd83087f096094",
   "metadata": {
    "collapsed": false,
    "id": "18cd83087f096094",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. 总结\n",
    "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
    "在本章节中，你将会学会：\n",
    "+ 如何使用模型进行 Lora 微调\n",
    "+ 微调数据集的准备和对齐\n",
    "+ 使用微调的模型进行推理"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
